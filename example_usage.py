"""
ClariAI Example Usage and Demonstrations

Comprehensive examples demonstrating ClariAI's capabilities for audio quality analysis,
training custom models, and integration with various systems.

GitHub Repository: https://github.com/kernelseed/audio-call-quality-analyzer
"""

import os
import json
import time
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional
import logging

# ClariAI imports
from audio_call_quality_model import ClariAIAnalyzer
from training_pipeline import ClariAITrainer
from huggingface_integration import ClariAIHubUploader

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_test_audio(duration: float = 5.0, 
                     sample_rate: int = 16000,
                     filename: str = "test_audio.wav") -> str:
    """
    Create a test audio file for demonstration purposes.
    
    Args:
        duration: Duration in seconds
        sample_rate: Sample rate
        filename: Output filename
        
    Returns:
        Path to created audio file
    """
    try:
        # Generate a simple sine wave with some noise
        t = np.linspace(0, duration, int(sample_rate * duration))
        
        # Create a speech-like signal with formants
        signal = (np.sin(2 * np.pi * 200 * t) * 0.3 +  # Fundamental frequency
                 np.sin(2 * np.pi * 800 * t) * 0.2 +   # First formant
                 np.sin(2 * np.pi * 1200 * t) * 0.1 +  # Second formant
                 np.random.normal(0, 0.05, len(t)))    # Noise
        
        # Add envelope to make it more speech-like
        envelope = np.exp(-t / duration) * (1 + 0.5 * np.sin(2 * np.pi * 2 * t))
        signal *= envelope
        
        # Normalize
        signal = signal / np.max(np.abs(signal)) * 0.8
        
        # Save audio file
        import soundfile as sf
        sf.write(filename, signal, sample_rate)
        
        logger.info(f"Created test audio file: {filename}")
        return filename
        
    except Exception as e:
        logger.error(f"Error creating test audio: {e}")
        raise

def demo_basic_analysis():
    """Demonstrate basic audio quality analysis."""
    print("\nüéµ ClariAI Basic Analysis Demo")
    print("=" * 40)
    
    # Create test audio
    audio_file = create_test_audio(duration=3.0, filename="demo_audio.wav")
    
    try:
        # Initialize ClariAI analyzer
        analyzer = ClariAIAnalyzer()
        
        # Analyze audio quality
        print(f"Analyzing audio: {audio_file}")
        start_time = time.time()
        results = analyzer.analyze_call_quality(audio_file)
        analysis_time = time.time() - start_time
        
        # Display results
        print(f"\nüìä Analysis Results (took {analysis_time:.2f}s)")
        print("-" * 30)
        print(f"Analysis Method: {results['analysis_method']}")
        print(f"Overall Quality: {results['quality_scores']['overall_quality']:.3f}")
        print(f"Clarity: {results['quality_scores']['clarity']:.3f}")
        print(f"Volume: {results['quality_scores']['volume']:.3f}")
        print(f"Noise Level: {results['quality_scores']['noise_level']:.3f}")
        
        # Display features
        print(f"\nüîç Extracted Features:")
        for feature, value in results['features'].items():
            print(f"  {feature}: {value:.3f}")
        
        return results
        
    except Exception as e:
        logger.error(f"Error in basic analysis demo: {e}")
        return None
    finally:
        # Cleanup
        if os.path.exists(audio_file):
            os.remove(audio_file)

def demo_training_pipeline():
    """Demonstrate training pipeline."""
    print("\nü§ñ ClariAI Training Pipeline Demo")
    print("=" * 40)
    
    try:
        # Initialize trainer
        trainer = ClariAITrainer()
        
        # Create sample training data
        print("Creating sample training data...")
        for i in range(5):
            # Create different quality audio samples
            quality_levels = ["excellent", "good", "poor"]
            quality = quality_levels[i % len(quality_levels)]
            
            audio_file = create_test_audio(
                duration=2.0, 
                filename=f"training_sample_{i}.wav"
            )
            
            # Add some variation to audio quality
            if quality == "poor":
                # Add more noise
                import soundfile as sf
                signal, sr = sf.read(audio_file)
                noise = np.random.normal(0, 0.1, len(signal))
                signal += noise
                sf.write(audio_file, signal, sr)
            elif quality == "excellent":
                # Clean signal
                import soundfile as sf
                signal, sr = sf.read(audio_file)
                signal = signal * 1.2  # Slightly louder
                sf.write(audio_file, signal, sr)
            
            trainer.add_training_sample(audio_file, quality)
        
        # Train model
        print("Training Random Forest model...")
        metrics = trainer.train_model("random_forest", optimize_hyperparameters=False)
        
        # Display training results
        print(f"\nüìà Training Results:")
        print(f"Model: {metrics['model_name']}")
        print(f"Test Accuracy: {metrics['test_accuracy']:.3f}")
        print(f"CV Mean: {metrics['cv_mean']:.3f} ¬± {metrics['cv_std']:.3f}")
        print(f"Samples: {metrics['n_samples']}")
        print(f"Features: {metrics['n_features']}")
        
        # Test prediction
        test_audio = create_test_audio(duration=1.0, filename="test_prediction.wav")
        prediction = trainer.predict_quality(test_audio)
        print(f"\nüîÆ Prediction Test:")
        print(f"Audio: {test_audio}")
        print(f"Predicted Quality: {prediction}")
        
        # Save model
        model_path = "demo_model"
        trainer.save_model(model_path)
        print(f"\nüíæ Model saved to: {model_path}")
        
        return trainer, metrics
        
    except Exception as e:
        logger.error(f"Error in training pipeline demo: {e}")
        return None, None
    finally:
        # Cleanup training files
        for i in range(5):
            audio_file = f"training_sample_{i}.wav"
            if os.path.exists(audio_file):
                os.remove(audio_file)
        if os.path.exists("test_prediction.wav"):
            os.remove("test_prediction.wav")

def demo_batch_processing():
    """Demonstrate batch processing capabilities."""
    print("\nüì¶ ClariAI Batch Processing Demo")
    print("=" * 40)
    
    try:
        # Create multiple test audio files
        audio_files = []
        for i in range(3):
            audio_file = create_test_audio(
                duration=2.0,
                filename=f"batch_audio_{i}.wav"
            )
            audio_files.append(audio_file)
        
        # Initialize analyzer
        analyzer = ClariAIAnalyzer()
        
        # Batch analysis
        print(f"Analyzing {len(audio_files)} audio files...")
        start_time = time.time()
        results = analyzer.batch_analyze(audio_files)
        batch_time = time.time() - start_time
        
        # Display results
        print(f"\nüìä Batch Analysis Results (took {batch_time:.2f}s)")
        print("-" * 40)
        
        for i, (audio_file, result) in enumerate(zip(audio_files, results)):
            print(f"\nFile {i+1}: {audio_file}")
            print(f"  Overall Quality: {result['quality_scores']['overall_quality']:.3f}")
            print(f"  Clarity: {result['quality_scores']['clarity']:.3f}")
            print(f"  Volume: {result['quality_scores']['volume']:.3f}")
            print(f"  Noise Level: {result['quality_scores']['noise_level']:.3f}")
        
        # Calculate average quality
        avg_quality = np.mean([r['quality_scores']['overall_quality'] for r in results])
        print(f"\nüìà Average Quality: {avg_quality:.3f}")
        
        return results
        
    except Exception as e:
        logger.error(f"Error in batch processing demo: {e}")
        return None
    finally:
        # Cleanup
        for audio_file in audio_files:
            if os.path.exists(audio_file):
                os.remove(audio_file)

def demo_custom_features():
    """Demonstrate custom feature extraction."""
    print("\nüîß ClariAI Custom Features Demo")
    print("=" * 40)
    
    try:
        # Create test audio
        audio_file = create_test_audio(duration=4.0, filename="custom_features_audio.wav")
        
        # Initialize analyzer
        analyzer = ClariAIAnalyzer()
        
        # Extract features
        print(f"Extracting features from: {audio_file}")
        features = analyzer.extract_audio_features(audio_file)
        
        # Display all features
        print(f"\nüîç Extracted Features:")
        print("-" * 30)
        for feature, value in features.items():
            print(f"{feature:20}: {value:8.3f}")
        
        # Feature analysis
        print(f"\nüìä Feature Analysis:")
        print(f"Highest value: {max(features.items(), key=lambda x: x[1])}")
        print(f"Lowest value: {min(features.items(), key=lambda x: x[1])}")
        print(f"Average value: {np.mean(list(features.values())):.3f}")
        
        return features
        
    except Exception as e:
        logger.error(f"Error in custom features demo: {e}")
        return None
    finally:
        # Cleanup
        if os.path.exists("custom_features_audio.wav"):
            os.remove("custom_features_audio.wav")

def demo_huggingface_integration():
    """Demonstrate Hugging Face integration (if available)."""
    print("\n‚òÅÔ∏è ClariAI Hugging Face Integration Demo")
    print("=" * 40)
    
    try:
        # Check if Hugging Face is available
        from huggingface_integration import ClariAIHubUploader
        
        # Initialize uploader (requires HF token)
        hf_token = os.getenv('HUGGINGFACE_HUB_TOKEN')
        if not hf_token:
            print("‚ö†Ô∏è  Hugging Face token not found. Set HUGGINGFACE_HUB_TOKEN environment variable.")
            print("   Skipping Hugging Face integration demo.")
            return None
        
        uploader = ClariAIHubUploader(hf_token=hf_token)
        
        # Create model card
        print("Creating model card...")
        model_card = uploader.create_model_card(
            model_name="clariai-demo-model",
            model_description="ClariAI demonstration model for audio quality analysis",
            tags=["audio", "quality-analysis", "demo", "clariai"],
            performance_metrics={
                "accuracy": 0.95,
                "precision": 0.94,
                "recall": 0.93,
                "f1_score": 0.935
            }
        )
        
        print("‚úÖ Model card created successfully")
        print(f"Model card length: {len(model_card)} characters")
        
        # List available models
        print("\nüîç Available ClariAI models:")
        models = uploader.list_models(limit=5)
        for model in models:
            print(f"  - {model['name']} by {model['author']}")
        
        return uploader
        
    except ImportError:
        print("‚ö†Ô∏è  Hugging Face integration not available. Install with: pip install huggingface-hub")
        return None
    except Exception as e:
        logger.error(f"Error in Hugging Face integration demo: {e}")
        return None

def cleanup_test_files():
    """Clean up any remaining test files."""
    test_files = [
        "test_audio.wav",
        "demo_audio.wav",
        "training_sample_0.wav",
        "training_sample_1.wav",
        "training_sample_2.wav",
        "training_sample_3.wav",
        "training_sample_4.wav",
        "test_prediction.wav",
        "batch_audio_0.wav",
        "batch_audio_1.wav",
        "batch_audio_2.wav",
        "custom_features_audio.wav"
    ]
    
    for file in test_files:
        if os.path.exists(file):
            os.remove(file)
            print(f"Cleaned up: {file}")

def main():
    """Main demonstration function."""
    print("üöÄ ClariAI Comprehensive Demo")
    print("=" * 50)
    print("Demonstrating ClariAI's audio quality analysis capabilities")
    print("GitHub: https://github.com/kernelseed/audio-call-quality-analyzer")
    
    try:
        # Run all demonstrations
        print("\n" + "="*50)
        demo_basic_analysis()
        
        print("\n" + "="*50)
        trainer, metrics = demo_training_pipeline()
        
        print("\n" + "="*50)
        demo_batch_processing()
        
        print("\n" + "="*50)
        demo_custom_features()
        
        print("\n" + "="*50)
        demo_huggingface_integration()
        
        print("\n" + "="*50)
        print("‚úÖ All demonstrations completed successfully!")
        
        # Display summary
        print("\nüìã ClariAI Demo Summary")
        print("-" * 30)
        print("‚úÖ Basic audio quality analysis")
        print("‚úÖ Custom model training pipeline")
        print("‚úÖ Batch processing capabilities")
        print("‚úÖ Advanced feature extraction")
        print("‚úÖ Hugging Face integration")
        print("\nüéØ ClariAI is ready for production use!")
        
    except Exception as e:
        logger.error(f"Error in main demo: {e}")
        print(f"\n‚ùå Demo failed: {e}")
    finally:
        # Cleanup
        cleanup_test_files()
        print("\nüßπ Cleanup completed")

if __name__ == "__main__":
    main()